{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boonecabaldev/pandas_exercises/blob/main/Pandas_Exercise_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Exercises #4"
      ],
      "metadata": {
        "id": "rvp444PcvmxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is another `pandas` exercise set. Your doin' grate."
      ],
      "metadata": {
        "id": "-pNHBwuaur1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1: Financial Data Analysis"
      ],
      "metadata": {
        "id": "0gUey_m2vhA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**File:** `stock_transactions.csv`\n",
        "\n",
        "```\n",
        "TransactionID,Symbol,Date,Type,Shares,Price\n",
        "T12345,AAPL,2023-11-20,Buy,100,150.50\n",
        "T23456,GOOG,2023-11-21,Sell,50,1250.25\n",
        "T34567,AAPL,2023-11-22,Buy,75,148.75\n",
        "T45678,MSFT,2023-11-23,Buy,200,285.30\n",
        "T56789,GOOG,2023-11-24,Buy,30,1265.10\n",
        "T67890,AAPL,2023-11-25,Sell,150,152.25\n",
        "```\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1. Read the CSV into a DataFrame, parsing `Date` as datetime.\n",
        "2. Calculate the total cost of buying and the total revenue from selling for each stock symbol.\n",
        "3. Determine the net profit or loss for each stock symbol.\n",
        "4. Find the stock with the highest total transaction volume (shares bought + shares sold)."
      ],
      "metadata": {
        "id": "CEAths8dvk6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Solution**"
      ],
      "metadata": {
        "id": "7OfTnIfovyfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deferred to Original Solution"
      ],
      "metadata": {
        "id": "5ANSMTmWv2Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Solution:**"
      ],
      "metadata": {
        "id": "ZaJMqsW4wSEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read CSV with date parsing\n",
        "df_transactions = pd.read_csv('sample_data/stock_transactions.csv', parse_dates=['Date'])\n",
        "\n",
        "# Calculate cost and revenue per symbol\n",
        "df_transactions['Cost'] = df_transactions['Shares'] * df_transactions['Price'] * (df_transactions['Type'] == 'Buy')\n",
        "df_transactions['Revenue'] = df_transactions['Shares'] * df_transactions['Price'] * (df_transactions['Type'] == 'Sell')\n",
        "\n",
        "cost_per_symbol = df_transactions.groupby('Symbol')['Cost'].sum()\n",
        "revenue_per_symbol = df_transactions.groupby('Symbol')['Revenue'].sum()\n",
        "\n",
        "# Net profit/loss\n",
        "net_profit_loss = revenue_per_symbol - cost_per_symbol\n",
        "print(\"\\nNet profit/loss per symbol:\")\n",
        "print(net_profit_loss.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "# Highest transaction volume\n",
        "transaction_volume = df_transactions.groupby('Symbol')['Shares'].sum()\n",
        "highest_volume_symbol = transaction_volume.idxmax()\n",
        "print(f\"\\nSymbol with highest transaction volume: {highest_volume_symbol}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TransactionID Symbol       Date Type  Shares   Price     Cost\n",
            "       T12345   AAPL 2023-11-20  Buy     100  150.50 15050.00\n",
            "       T23456   GOOG 2023-11-21 Sell      50 1250.25     0.00\n",
            "       T34567   AAPL 2023-11-22  Buy      75  148.75 11156.25\n",
            "       T45678   MSFT 2023-11-23  Buy     200  285.30 57060.00\n",
            "       T56789   GOOG 2023-11-24  Buy      30 1265.10 37953.00\n",
            "       T67890   AAPL 2023-11-25 Sell     150  152.25     0.00\n",
            "\n",
            "Net profit/loss per symbol:\n",
            "| Symbol   | 0        |\n",
            "|:---------|:---------|\n",
            "| AAPL     | -3368.75 |\n",
            "| GOOG     | 24559.5  |\n",
            "| MSFT     | -57060   |\n",
            "\n",
            "Symbol with highest transaction volume: AAPL\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnNdGiXFur1P",
        "outputId": "9b9b3788-4cd3-450d-f9e9-9e8adf1f524c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2:  Customer Segmentation"
      ],
      "metadata": {
        "id": "EiWsBmFhwB_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**File:** `customer_data.csv`\n",
        "\n",
        "```\n",
        "CustomerID,Age,Gender,Income,SpendingScore\n",
        "1,19,Male,15000,39\n",
        "2,21,Male,15000,81\n",
        "3,20,Female,16000,6\n",
        "4,23,Female,16000,77\n",
        "5,31,Female,17000,40\n",
        "```\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1. Read the CSV into a DataFrame.\n",
        "2. Use k-means clustering to segment customers into 3 groups based on `Age`, `Income`, and `SpendingScore`.\n",
        "3. Add a `Segment` column to the DataFrame indicating the assigned cluster for each customer (e.g., 'Segment 0', 'Segment 1', 'Segment 2')."
      ],
      "metadata": {
        "id": "vpiHcDuGur1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Solution**"
      ],
      "metadata": {
        "id": "7UAJexGXwHJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defer to Original Solution\n",
        "\n",
        "# This is beyond the pandas stuff I'm doing at this juncture"
      ],
      "metadata": {
        "id": "IFyjqAz9wJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Solution:**"
      ],
      "metadata": {
        "id": "Z16hn_J5wNwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Read CSV\n",
        "df_customers = pd.read_csv('sample_data/customer_data.csv')\n",
        "\n",
        "# Clustering\n",
        "X = df_customers[['Age', 'Income', 'SpendingScore']]\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(X)\n",
        "\n",
        "# Add segment labels\n",
        "df_customers['Segment'] = ['Segment ' + str(label) for label in kmeans.labels_]\n",
        "\n",
        "print(\"\\nCustomer data with segments:\")\n",
        "print(df_customers.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Customer data with segments:\n",
            "| CustomerID   | Age   | Gender   | Income   | SpendingScore   | Segment   |\n",
            "|:-------------|:------|:---------|:---------|:----------------|:----------|\n",
            "| 1            | 19    | Male     | 15000    | 39              | Segment 1 |\n",
            "| 2            | 21    | Male     | 15000    | 81              | Segment 1 |\n",
            "| 3            | 20    | Female   | 16000    | 6               | Segment 2 |\n",
            "| 4            | 23    | Female   | 16000    | 77              | Segment 2 |\n",
            "| 5            | 31    | Female   | 17000    | 40              | Segment 0 |\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxgJmS1Zur1T",
        "outputId": "153b99de-018e-45a4-e88a-3b5538f95225"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3:  Text Data Cleaning"
      ],
      "metadata": {
        "id": "4Sxfrf5jur1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**File:** `product_reviews.txt` (One review per line)\n",
        "\n",
        "```\n",
        "This product is amazing! 5 stars\n",
        "I love it!\n",
        "It's okay, could be better.\n",
        "Not worth the price.\n",
        "The best purchase I've made this year.\n",
        "```\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1. Read the text file into a Series.\n",
        "2. Convert all reviews to lowercase.\n",
        "3. Remove punctuation from the reviews.\n",
        "4. Calculate the frequency of each word in all reviews."
      ],
      "metadata": {
        "id": "eo5X51K3wd0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My Solution**"
      ],
      "metadata": {
        "id": "6lhpyBy0wign"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defer to Original Solution\n",
        "\n",
        "# Will be studing this"
      ],
      "metadata": {
        "id": "sYkBZSzNwknZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original Solution:**"
      ],
      "metadata": {
        "id": "u8cwyZu_wf8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read text file into Series\n",
        "with open('sample_data/product_reviews.txt', 'r') as file:\n",
        "    reviews = pd.Series(file.read().splitlines())\n",
        "\n",
        "# Lowercase and remove punctuation\n",
        "reviews = reviews.str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# Word frequency\n",
        "all_words = ' '.join(reviews).split()\n",
        "word_freq = pd.Series(all_words).value_counts()\n",
        "\n",
        "print(\"\\nWord frequency:\")\n",
        "print(word_freq.head(10).to_markdown(numalign=\"left\", stralign=\"left\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word frequency:\n",
            "|          | count   |\n",
            "|:---------|:--------|\n",
            "| this     | 2       |\n",
            "| the      | 2       |\n",
            "| be       | 1       |\n",
            "| made     | 1       |\n",
            "| ive      | 1       |\n",
            "| purchase | 1       |\n",
            "| best     | 1       |\n",
            "| price    | 1       |\n",
            "| worth    | 1       |\n",
            "| not      | 1       |\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp7ZsJjiur1V",
        "outputId": "70db51f4-d0be-4730-9278-77a8beef7ecd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let me know if you'd like any clarification or more practice examples!"
      ],
      "metadata": {
        "id": "Y1w17IQNur1V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}